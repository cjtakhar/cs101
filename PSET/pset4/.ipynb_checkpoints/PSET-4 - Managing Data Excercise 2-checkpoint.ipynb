{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39ba724",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue;border: 2px solid gray;\">\n",
    "    <h2 style =\"text-align:center; padding-top:5px;\"> CS 101 - Foundation of Data Science and Engineering  </h2><br>\n",
    "    <p style=\"text-align:center;padding:5px; fontt-size:14px\"><b> PSET-4 - Managing Data Excercise-2 (100 pts)<b></p> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048c845d",
   "metadata": {},
   "source": [
    "### This is an individual assignment. No collaboration is allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabaa058",
   "metadata": {},
   "source": [
    "### Assignment Goal:\n",
    " \n",
    "**Part-1 : Explore Pandas, perform data cleaning using Pandas.**\n",
    "\n",
    "**Part-2 : Generate random sample data in SQL**\n",
    "\n",
    "**Part-3 : Practice writing SQL queries**\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad46be2",
   "metadata": {},
   "source": [
    "**Start by reviewing the provided file nj_teachers_salaries_pset4.csv. Examine the column names, data types of this data file. After reviewing this file please provide your solutions for the questions below.**\n",
    "\n",
    "**Note: The file has identical columns that you worked on PSET-3, however all the data are not identical**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d0f1b",
   "metadata": {},
   "source": [
    "**Resources:**<br>\n",
    "**https://pandas.pydata.org/docs/reference/frame.html**<br>\n",
    "**Module 4 & Module 5 Lectures**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9d649",
   "metadata": {},
   "source": [
    "**Please feel free to create new cells in your notebook for completing the assignment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5709bcb",
   "metadata": {},
   "source": [
    "# Part-1 (60 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe347e3",
   "metadata": {},
   "source": [
    "**In this part you will be working with Pandas to explore and clean data. For each of the questions, please make sure that you show your work on what was done in each step.**\n",
    "\n",
    "**For Example if you drop rows, be sure to show the how many rows were dropped at each step. You can use \n",
    "df.shape to show before and after count.**\n",
    "\n",
    "**For Questions 3-5 that involve modifying your values, you need to show us few rows where the modification was done. \n",
    "As an example you are looking at df['experience_total'] column and you discover that the column has values that are not numerical. You go ahead and set the values as np.NAN.  You should show that those values were indeed set  as nan. You can use print statements or simply create a new cell and show some example rows. Please display relevant rows and not the full dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8464d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector as sq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d3ca40",
   "metadata": {},
   "source": [
    "## Question-1 (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e434b31",
   "metadata": {},
   "source": [
    "### Create a dataframe called df using the provided csv file nj_teachers_salaries_pset4.csv. Use df.info() to get the information about the columns, non-null values, and data type inferred by Pandas for each column. \n",
    "\n",
    "**Pandas tries to infer the data type of each column. However if you have a numerical column, with an invalid value (such as a string), it will infer it as an object. String values are inferred as object data type.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "327c0e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0x/msstf8r11wg2nt4pzb707v480000gn/T/ipykernel_26910/1191264309.py:2: DtypeWarning: Columns (7,8,13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Users/kt/Harvard/CS101/PSET/pset4/nj_teachers_salaries_pset4.csv')\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.read_csv('/Users/kt/Harvard/CS101/PSET/pset4/nj_teachers_salaries_pset4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd3ffb4-444d-4ccb-9211-f892d4c79ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100005 entries, 0 to 100004\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   id                   99998 non-null   float64\n",
      " 1   last_name            100003 non-null  object \n",
      " 2   first_name           100003 non-null  object \n",
      " 3   county               100003 non-null  object \n",
      " 4   district             100003 non-null  object \n",
      " 5   school               100003 non-null  object \n",
      " 6   primary_job          100003 non-null  object \n",
      " 7   fte                  100003 non-null  object \n",
      " 8   salary               99983 non-null   object \n",
      " 9   certificate          100003 non-null  object \n",
      " 10  subcategory          100003 non-null  object \n",
      " 11  teaching_route       100003 non-null  object \n",
      " 12  highly_qualified     100003 non-null  object \n",
      " 13  experience_district  100003 non-null  object \n",
      " 14  experience_nj        100003 non-null  object \n",
      " 15  experience_total     99983 non-null   object \n",
      "dtypes: float64(1), object(15)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Display info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0fe64",
   "metadata": {},
   "source": [
    "## Question-2 (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2028011c",
   "metadata": {},
   "source": [
    "### Drop rows that have all values as NaN. (Recall from lecture that you have to set the parameter how='all') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cf108bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that have all values as NaN\n",
    "df.dropna(how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d34185d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question-3 (20 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d614e58",
   "metadata": {},
   "source": [
    "### Numerical Columns :\n",
    "\n",
    "### Identify numerical columns excluding id column, remove any invalid characters from numerical columns by first setting it to np.NAN , and finally drop rows containing NaN values. (5))\n",
    "\n",
    "### Set the correct data type for each of the numerical columns (i.e. int , float) (1)\n",
    "\n",
    "## Check the id column. Set the correct id number for rows that are NA/NaN. Set the correct dtype.(5)\n",
    "\n",
    "### At the end of this step your dataframe should not contain any invalid values for numerical values. Only invalid/missing values should have been dropped. (5)\n",
    "\n",
    "\n",
    "### Please be sure to show your work, meaning , show few example rows that were actually modified. (4)   \n",
    "\n",
    "### Note : do not reset the index of the dataframe at any point. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5171405b-8861-4e0e-a7d6-b8a6d6b362cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns (excluding 'id')\n",
    "numerical_columns = ['fte', 'salary', 'experience_district', 'experience_nj', 'experience_total']\n",
    "\n",
    "# Replace non-numeric values with NaN\n",
    "df[numerical_columns] = df[numerical_columns].replace(r'[^0-9.]', np.nan, regex=True)\n",
    "\n",
    "# Drop rows with NaN values in any numerical column\n",
    "df.dropna(subset=numerical_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "032eab69-ce70-490b-9655-4d3b3f7100db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numerical columns to the correct types\n",
    "df['fte'] = df['fte'].astype(float)  # Float\n",
    "df['salary'] = df['salary'].astype(float)  # Float\n",
    "df['experience_district'] = df['experience_district'].astype(float)  # Float\n",
    "df['experience_nj'] = df['experience_nj'].astype(float)  # Float\n",
    "df['experience_total'] = df['experience_total'].astype(float)  # Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13a48ba9-1a68-4397-9003-9c5f20f1042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing ID values with sequential numbers starting from max existing ID + 1\n",
    "next_id = int(df['id'].max()) + 1\n",
    "df.loc[df['id'].isna(), 'id'] = range(next_id, next_id + df['id'].isna().sum())\n",
    "\n",
    "# Convert ID column to integer\n",
    "df['id'] = df['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32179431-d275-4c55-87fd-8c4617ab6a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples of fixed 'id' values:\n",
      "Empty DataFrame\n",
      "Columns: [id, last_name, first_name, county, district, school, primary_job, fte, salary, certificate, subcategory, teaching_route, highly_qualified, experience_district, experience_nj, experience_total]\n",
      "Index: []\n",
      "\n",
      "Final Check: Any remaining NaNs in numerical columns?\n",
      "id                     0\n",
      "fte                    0\n",
      "salary                 0\n",
      "experience_district    0\n",
      "experience_nj          0\n",
      "experience_total       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show a few examples of fixed rows\n",
    "print(\"\\nExamples of fixed 'id' values:\")\n",
    "print(df.loc[df['id'].isna()].head(5))  # Should return an empty DataFrame if all NaNs were fixed\n",
    "\n",
    "# Final check to ensure no missing values in numerical columns\n",
    "print(\"\\nFinal Check: Any remaining NaNs in numerical columns?\")\n",
    "print(df[['id', 'fte', 'salary', 'experience_district', 'experience_nj', 'experience_total']].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624f3e6",
   "metadata": {},
   "source": [
    "## Question-4 (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db700d9",
   "metadata": {},
   "source": [
    "### String Columns:\n",
    "\n",
    "### Identify string/object columns. Remove any leading and trailing spaces. This can be applied to all string columns (3)\n",
    "### Show example rows/columns where leading and trailing spaces were removed.Hint : first_name,last_name have data values with leading and trailing spaces. Show at least 2 such examples where data values were modified for these columns. (2)\n",
    "\n",
    "### No rows should be dropped.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75a36ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify string/object columns\n",
    "string_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Remove leading and trailing spaces from all string columns\n",
    "df[string_columns] = df[string_columns].apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17eb809d-1c57-47f8-9cef-9deb1ac027a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples where leading/trailing spaces were removed (first_name, last_name):\n",
      "Empty DataFrame\n",
      "Columns: [first_name, last_name]\n",
      "Index: []\n",
      "\n",
      "Final Check: Number of rows before and after cleaning\n",
      "Original Row Count: 99959\n"
     ]
    }
   ],
   "source": [
    "# Show examples where spaces were removed\n",
    "modified_names = df[\n",
    "    (df['first_name'].str.startswith(' ')) | (df['first_name'].str.endswith(' ')) |\n",
    "    (df['last_name'].str.startswith(' ')) | (df['last_name'].str.endswith(' '))\n",
    "]\n",
    "\n",
    "# Display a few modified rows\n",
    "print(\"\\nExamples where leading/trailing spaces were removed (first_name, last_name):\")\n",
    "print(modified_names[['first_name', 'last_name']].head(2))  # Show at least 2 examples\n",
    "\n",
    "# Final check to confirm no rows were dropped\n",
    "print(\"\\nFinal Check: Number of rows before and after cleaning\")\n",
    "print(f\"Original Row Count: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f832694",
   "metadata": {},
   "source": [
    "## Question-5 (20 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06952cce",
   "metadata": {},
   "source": [
    "### Additional Cleaning - String Column :\n",
    "\n",
    "### Perform additional cleaning on string columns. Remove any special/invalid characters from the string columns.\n",
    "\n",
    "### Example :\n",
    "### df['primary_job'] contains a value 'Family & Consumer Sciences â€“ Apparel, Textiles And Interiors'.\n",
    "\n",
    "### The special character should be removed to give the value 'Family & Consumer Sciences  Apparel, Textiles And Interiors' (2.5 pts)\n",
    "\n",
    "\n",
    "### Perform data cleaning on at least 3 string columns. You will have to identify data values in your string columns, and remove any special characters. (7.5) pts\n",
    "\n",
    "### You should try to avoid setting string columns to np.NAN , and dropping it. However, it is ok if you set some rows to np.NAN and drop it for which values are completely invalid. In the end you should have approximately the same number of rows that you had after finishing Question 3. \n",
    "\n",
    "### We are not looking for a perfect solution. The data may still consist of invalid values. We are more interested in seeing how you have applied your learning to this assignment. \n",
    "\n",
    "\n",
    "### In all cases please show your work, meaning show us few example rows/columns where the data values were actually modified. (10 pts)\n",
    "\n",
    "### Note : In general letters, numbers, punctuations , & , /, \\, () , - , :, s'_,.,?!&/-:#@   are considered valid. You can choose to include more characters.  However, for first name and last name, teaching_route, subcategory you will want to choose only specific characters to be considered valid. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f8858c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify string columns\n",
    "string_columns = df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08c11dbc-3ef5-4cfe-959e-b4236d5a37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define valid character patterns for different string columns (using raw strings r\"\")\n",
    "valid_patterns = {\n",
    "    'primary_job': r\"[^A-Za-z0-9\\s&\\-,/]\",  # Letters, numbers, spaces, &, -, /\n",
    "    'teaching_route': r\"[^A-Za-z\\s\\-']\",  # Letters, spaces, -, '\n",
    "    'subcategory': r\"[^A-Za-z\\s\\-,.:]\",  # Letters, spaces, -, ., :\n",
    "    'first_name': r\"[^A-Za-z\\-' ]\",  # Letters, hyphens, and apostrophes\n",
    "    'last_name': r\"[^A-Za-z\\-' ]\"  # Letters, hyphens, and apostrophes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "721c4c0a-e841-498e-9201-d648433c0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply regex cleaning to respective columns\n",
    "for col, pattern in valid_patterns.items():\n",
    "    df[col] = df[col].str.replace(pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e277b5b-f270-419c-b10c-b3fc92317c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify modified rows\n",
    "modified_rows = df[string_columns].copy()\n",
    "for col in valid_patterns.keys():\n",
    "    modified_rows[col] = df[col] != df[col].str.replace(valid_patterns[col], '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c312c0e9-dc91-4da4-a1b1-ae34f803e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples of modified rows\n",
    "modified_rows = df[modified_rows.any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d308d777-a762-4f8d-acf5-654eb3cbb853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples of modified string column values:\n",
      "                       primary_job teaching_route subcategory first_name  \\\n",
      "0    Elementary School Teacher K-5    Traditional  General ed    William   \n",
      "1                              Art    Traditional  General ed      Kelly   \n",
      "2                     Kindergarten      Alternate  General ed  Crystal A   \n",
      "3  Elementary Kindergraten-8 Grade    Traditional  Special ed     Isaiah   \n",
      "4           English Non-elementary    Traditional  General ed     Dustin   \n",
      "\n",
      "  last_name  \n",
      "0   Heckman  \n",
      "1      Bird  \n",
      "2    Aikens  \n",
      "3   Leonard  \n",
      "4    Hinton  \n"
     ]
    }
   ],
   "source": [
    "# Display a few examples of modified rows\n",
    "print(\"\\nExamples of modified string column values:\")\n",
    "print(modified_rows[['primary_job', 'teaching_route', 'subcategory', 'first_name', 'last_name']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c4f8cf9-b7fe-450a-a0d4-d317f8489a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final Check: Number of rows before and after cleaning\n",
      "Row count after Question 3: 99959\n"
     ]
    }
   ],
   "source": [
    "# Final row count check to ensure minimal data loss\n",
    "print(\"\\n Final Check: Number of rows before and after cleaning\")\n",
    "print(f\"Row count after Question 3: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6af6de",
   "metadata": {},
   "source": [
    "## Question -7 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7685921",
   "metadata": {},
   "source": [
    "### Save your cleaned dataframe as  cleaned_data.csv. Be sure to set the parameter index = False to avoid saving the index as an extra column\n",
    "\n",
    "ex:\n",
    "df.to_csv(\"cleaned_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c6c91e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned data has been successfully saved as 'cleaned_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataframe as 'cleaned_data.csv'\n",
    "df.to_csv(\"cleaned_data.csv\", index=False)\n",
    "\n",
    "print(\"\\nCleaned data has been successfully saved as 'cleaned_data.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05cbf6",
   "metadata": {},
   "source": [
    "## Question -8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1908b9",
   "metadata": {},
   "source": [
    "### Similar to PSET-3 \n",
    "\n",
    "### 8.1 Connect to your MySql database using your username and password. Name the cursor returned from the mysql connection object as mycursor. (1 pts)\n",
    "\n",
    "\n",
    "### 8.2 Use the same database as PSET-3 nj_state_teachers_salaries, or if you have deleted it create a database called nj_state_teachers_salaries\n",
    "\n",
    "\n",
    "### 8.3 Create a table called teachers_salaries_pset4 with all the columns in your cleaned_data.csv. For this part ,be sure to use appropriate data type for all the columns.  If you are facing difficulty creating a column with Float or bool or int , it is ok to store it as TEXT. (MAX 2 allowed for numerical columns being stored as TEXT) (3 pts)\n",
    "\n",
    "\n",
    "### 8.4 Using LOAD DATA statement (as discussed in Module 4 lectures) load the data from cleaned_data.csv to your table created in 8.3. Use of OPTIONALLY ENCLOSED BY  clause and TERMINATED by clause is recommended. (3 pts)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0aa0e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL connection\n",
    "mydb = sq.connect(\n",
    "    host=\"localhost\", \n",
    "    user=\"cs101\",\n",
    "    password=\"dataisfun\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "mycursor = mydb.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3123aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the database if it doesn't exist\n",
    "mycursor.execute(\"CREATE DATABASE IF NOT EXISTS nj_state_teachers_salaries\")\n",
    "\n",
    "# Use the database\n",
    "mycursor.execute(\"USE nj_state_teachers_salaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9c02aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 'teachers_salaries_pset4' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Drop table if it already exists to avoid conflicts\n",
    "mycursor.execute(\"DROP TABLE IF EXISTS teachers_salaries_pset4\")\n",
    "\n",
    "# Create table with appropriate data types\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE teachers_salaries_pset4 (\n",
    "    id INT PRIMARY KEY,\n",
    "    last_name VARCHAR(50),\n",
    "    first_name VARCHAR(50),\n",
    "    county VARCHAR(50),\n",
    "    district VARCHAR(100),\n",
    "    school VARCHAR(100),\n",
    "    primary_job VARCHAR(150),\n",
    "    fte FLOAT,  -- Float data type\n",
    "    salary FLOAT,  -- Float data type\n",
    "    certificate VARCHAR(50),\n",
    "    subcategory VARCHAR(50),\n",
    "    teaching_route VARCHAR(50),\n",
    "    highly_qualified VARCHAR(100),\n",
    "    experience_district FLOAT,  -- Float because we kept decimals\n",
    "    experience_nj FLOAT,  -- Float because we kept decimals\n",
    "    experience_total FLOAT  -- Float because we kept decimals\n",
    ");\n",
    "\"\"\"\n",
    "# Execute the table creation query\n",
    "mycursor.execute(create_table_query)\n",
    "\n",
    "print(\"\\nTable 'teachers_salaries_pset4' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "262fc1e9-46f9-46e4-a636-e9a726e1b0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data loaded successfully into 'teachers_salaries_pset4'.\n"
     ]
    }
   ],
   "source": [
    "# Load data from cleaned_data.csv into the MySQL table\n",
    "load_data_query = \"\"\"\n",
    "LOAD DATA INFILE '/Users/kt/Harvard/CS101/PSET/pset4/cleaned_data.csv' \n",
    "INTO TABLE teachers_salaries_pset4 \n",
    "FIELDS TERMINATED BY ',' \n",
    "OPTIONALLY ENCLOSED BY '\"' \n",
    "LINES TERMINATED BY '\\n' \n",
    "IGNORE 1 ROWS;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the data loading query\n",
    "mycursor.execute(load_data_query)\n",
    "\n",
    "# Commit the changes\n",
    "mydb.commit()\n",
    "\n",
    "print(\"\\nData loaded successfully into 'teachers_salaries_pset4'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7cb666",
   "metadata": {},
   "source": [
    "### Question 9 - For this question you are only required to run the cells. To get credit  your code from Question 8 must have been successfully run, and executed. No credit will be awarded if data was loaded using MySQL workbench. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81271dfc",
   "metadata": {},
   "source": [
    "## Question 9 (5 pts)\n",
    "\n",
    "Run the 2 cells below. The code checks if all the data rows and columns were stored in the database. \n",
    "\n",
    "The code below assumes that you named your cursor object as mycursor(As specified in Question-8). If you named it differently, you can rename mycursor to match the variable name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c84b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in teachers_salaries table : 99959\n"
     ]
    }
   ],
   "source": [
    "cmd = \"select count(*) from \\\n",
    "                 nj_state_teachers_salaries.teachers_salaries_pset4 \"\n",
    "mycursor.execute(cmd)\n",
    "count = mycursor.fetchone()[0]\n",
    "\n",
    "print(f\"Number of rows in teachers_salaries table : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9f8d503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in teachers_salaries table : 16\n"
     ]
    }
   ],
   "source": [
    "cmd = \"\"\"SELECT COUNT(*) \\\n",
    "                FROM INFORMATION_SCHEMA.COLUMNS \\\n",
    "                WHERE table_schema = 'nj_state_teachers_salaries' \\\n",
    "                AND table_name = 'teachers_salaries_pset4'\"\"\"\n",
    "mycursor.execute(cmd)\n",
    "count = mycursor.fetchone()[0]\n",
    "print(f\"Number of columns in teachers_salaries table : {count}\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203aacd",
   "metadata": {},
   "source": [
    "# End of Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b47ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c82f9052",
   "metadata": {},
   "source": [
    "### For both Part-2 and Part-3 you will need to work on MySQL workbench. For both parts you must submit .sql files. More information below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29229e41",
   "metadata": {},
   "source": [
    "# Part-2 (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5727a55",
   "metadata": {},
   "source": [
    "**For this part you will generate a random sample data from the table you created in Part-1 and save it as a csv file. Generating random samples have many use cases in the real world. For example, you are a developer who is working on a software application that requires access to a critical database. Instead you maybe given only a sample of data to work with to develop your application. Another use case is bootstrapping in statistics, or when you test your models with samples of data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6daab5",
   "metadata": {},
   "source": [
    "## Question 1 (8 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6381b9",
   "metadata": {},
   "source": [
    "### Use a SELECT statement to generate and output a random sample to : \n",
    "### Include all columns \n",
    "### Include field (column) headings \n",
    "### Randomly select 777 records with a seed value of 7 \n",
    "### Output results to a csv file named sample.csv \n",
    "### save your sql as  output.sql . You will submit this file as a part of this assignment. \n",
    "\n",
    "**You will find module 5 lecture on SQL Random Sample Generation useful**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd4a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee5c6647",
   "metadata": {},
   "source": [
    "## Question 2 (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09885ed7",
   "metadata": {},
   "source": [
    "### Create a dataframe using sample.csv generated from Question-1. Display the first 5 rows, and last 5 rows. Print the shape of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bcf04910",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/kt/Harvard/CS101/PSET/pset4/sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f9f6892e-a68e-4044-a7c0-6540d176006c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "    5907  Velasquez    Carl Hunterdon  South Hunterdon Regional  \\\n",
      "0  91649      Evans   James    Mercer              Hamilton Twp   \n",
      "1  33656      Davis  Amanda    Mercer  Hopewell Valley Regional   \n",
      "2  37479  Mcconnell  Robert    Mercer  Hopewell Valley Regional   \n",
      "3  63816    Francis  Elijah  Monmouth               Neptune Twp   \n",
      "4  29195     Fisher   David    Camden               Camden City   \n",
      "\n",
      "                 West Amwell Twp School  \\\n",
      "0             Hamilton North-nottingham   \n",
      "1   Hopewell Valley Central High School   \n",
      "2              Timberlane Middle School   \n",
      "3   Shark River Hills Elementary School   \n",
      "4  Creative Arts Morgan Village Academy   \n",
      "\n",
      "           Elementary Kindergraten-8 Grade  0.5   74437  Standard certificate  \\\n",
      "0            Elementary School Teacher K-5  0.8   67426                  CEAS   \n",
      "1              Health & Physical Education  0.8   70399  Standard certificate   \n",
      "2                Resource Program In-class  1.0  110165                  CEAS   \n",
      "3                              Music Vocal  0.8  105773  Standard certificate   \n",
      "4  Reading Development/remedial Elementary  0.5   58229                  CEAS   \n",
      "\n",
      "   Special ed  Traditional                 Not highly qualified   9  9.1  9.2  \n",
      "0  Special ed  Traditional  Doesn't need to be highly qualified  18   18   18  \n",
      "1  General ed  Traditional  Doesn't need to be highly qualified  13    8   23  \n",
      "2  Special ed  Traditional  Doesn't need to be highly qualified  19   31   35  \n",
      "3  General ed    Alternate                 Not highly qualified  13   11   31  \n",
      "4  General ed    Alternate                 Not highly qualified  20   35   32  \n",
      "\n",
      "Last 5 rows:\n",
      "      5907 Velasquez         Carl   Hunterdon South Hunterdon Regional  \\\n",
      "771  76099    Taylor      Monique      Camden            Waterford Twp   \n",
      "772  13819  Robinson        Laura      Bergen            Fort Lee Boro   \n",
      "773  32639    Mclean       Steven  Burlington            Riverside Twp   \n",
      "774  87334     David     Jennifer       Essex        Essex Co Voc-tech   \n",
      "775  83195   Serrano  Christopher      Bergen             Oakland Boro   \n",
      "\n",
      "          West Amwell Twp School  Elementary Kindergraten-8 Grade  0.5  \\\n",
      "771   Thomas Richards Elementary  Lang Arts/literacy Grades 5 - 8  0.8   \n",
      "772                 School No. 1  Assistant Principal High School  0.8   \n",
      "773  Riverside Elementary School  Elementary Kindergraten-8 Grade  0.8   \n",
      "774           West Caldwell Tech              Math Non-elementary  1.0   \n",
      "775         Valley Middle School    Elementary School Teacher K-5  1.0   \n",
      "\n",
      "      74437  Standard certificate  Special ed  Traditional  \\\n",
      "771  110102                  CEAS  Special ed    Alternate   \n",
      "772   66928                  CEAS  Special ed    Alternate   \n",
      "773   92725                  CEAS  General ed    Alternate   \n",
      "774   93221                  CEAS  General ed  Traditional   \n",
      "775   92030  Standard certificate  Special ed    Alternate   \n",
      "\n",
      "                    Not highly qualified   9  9.1  9.2  \n",
      "771                 Not highly qualified  37   33   39  \n",
      "772  Doesn't need to be highly qualified   9    9    9  \n",
      "773  Doesn't need to be highly qualified  18   18   18  \n",
      "774  Doesn't need to be highly qualified  23   27   23  \n",
      "775                 Not highly qualified  11   17   17  \n",
      "\n",
      "Shape of the dataframe: (776, 16)\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head(5))\n",
    "\n",
    "# Display the last 5 rows\n",
    "print(\"\\nLast 5 rows:\")\n",
    "print(df.tail(5))\n",
    "\n",
    "# Print the shape of the dataframe\n",
    "print(\"\\nShape of the dataframe:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d13a27",
   "metadata": {},
   "source": [
    "# Part-3 (30 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bfaae8",
   "metadata": {},
   "source": [
    "**For this part you will work on sql queries. You will write your queries for the provided dataset teachersample.csv. We could have asked you to write the queries based on the existing table nj_state_teachers_salaries.teachers_salaries_pset4 , however everyone's data cleaning process will be different resulting in different dataset.** \n",
    "\n",
    "**All work need to be done in MySQL workbench**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867b4ea",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced2812",
   "metadata": {},
   "source": [
    "### Create a table called salaries within the nj_state_teachers_salaries database. Load the data in to the table from the provided file teachersample.csv. The teachersample.csv does not contain the id column. Please modify your code to work with this csv file. \n",
    "\n",
    "### You don't need to submit the code for this. This table is intended only for queries in Question-2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500f520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbb786aa",
   "metadata": {},
   "source": [
    "## Question 2 (30 pts)\n",
    "## Each query is worth 3 pts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db6f76d",
   "metadata": {},
   "source": [
    "### Write the following queries in MySQL workbench, and name the file queries.sql.  The file you submit should have the exact name for you to get credit. We will run your query, so you don't need to capture the output. The file should include only the 10 queries. Be sure to test it before submission. \n",
    "\n",
    "**Example Query for your reference:**\n",
    "\n",
    "**select count(*) from nj_state_teachers_salaries.salaries;**\n",
    "\n",
    "#### Note : Please include the name of the database and the table in each query as shown in the above example. End each query with a semicolon as shown in example.Your file queries.sql should be able to execute any any machine that has the nj_state_teachers_salaries database and the salaries table.  We will deduct upto 10 pts if queries.sql does not execute. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f160c0f-0f6c-4901-b922-94c994454d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3848fb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Calculate the average salary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e5c0a",
   "metadata": {},
   "source": [
    "### 2. Calculate the number of people whose salary is more than 150,000. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18956d6",
   "metadata": {},
   "source": [
    "### 3. Get the last name of the ones who make more than 150,000 but have less than 5 years of total experience "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6896e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86469e13",
   "metadata": {},
   "source": [
    "### 4. Get the highest salary for Preschool, School Counselor, Principal (anyone with the word Principal in the title), School Psychologist, and Kindergarten. (These are individual queries.  You should have 5 separate queries.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb4a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63d4758e",
   "metadata": {},
   "source": [
    "### 5. Get the last name, first name, and salary of the lowest earner who works in Atlantic City "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78a518",
   "metadata": {},
   "source": [
    "### 6. Get the total number of employees working in Passaic City with more than ten years of total experience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d94e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588dbd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad18a901",
   "metadata": {},
   "source": [
    "## Submission on Gradescope\n",
    "\n",
    "**Gradescope canvas left menu -> Gradescop -> PSET 4: Managing Data Excercise 2**\n",
    "\n",
    "**Submission :**\n",
    "\n",
    "**Part -1  : This jupyter notebook, and a pdf of this notebook.** \n",
    "\n",
    "**Part -2 : output.sql and sample.csv**\n",
    "\n",
    "**Part -3 :  queries.sql containing all your queries.  This file should only include the sql queries. Please don't include the code that created the salaries table.** \n",
    "\n",
    "\n",
    "\n",
    "**To create a pdf of this notebook :  In your browser open print, and save as pdf. Name the pdf LastNameFirstName.pdf\n",
    "example: DoeJohn.pdf**\n",
    "\n",
    "**Name this jupyter notebook with the same format LastNameFirstName.ipynb**\n",
    "\n",
    "\n",
    "**Make sure that your notebook has been run before creating pdf. Any outputs from running the code needs to be clearly visible. We need all the files from Part-1, Part-2, and Part-3 to assign you grades.** \n",
    "\n",
    "\n",
    "**Drop all the files in gradescope under PSET 4: Managing Data Exercise 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8950c84c-7936-44fe-b9e0-8161cbff16fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1d3c134-b90a-48e7-9601-f1b640f045c1",
   "metadata": {},
   "source": [
    "### Submission Note (Please read)\n",
    "\n",
    "**After submitting your files on Gradescope , You may an error that says**\n",
    "\n",
    "**\"The autograder failed to execute correctly. Contact your course staff for help in debugging this issue. Make sure to include a link to this page so that they can help you most effectively.\"**\n",
    "\n",
    "### You don't have to take any action , and you do not need to contact us. The error is beacuse of some internal setup on Gradescope. As long as you have followed the specs, and submitted all the required files, you are good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba8b5cb-2696-4206-ab78-5ba338871a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
