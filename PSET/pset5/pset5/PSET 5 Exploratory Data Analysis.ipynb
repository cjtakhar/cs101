{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfdad8ff",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue;border: 2px solid gray;\">\n",
    "    <h2 style =\"text-align:center; padding-top:5px;\"> CS 101 - Foundation of Data Science and Engineering  </h2><br>\n",
    "    <p style=\"text-align:center;padding:5px; fontt-size:14px\"><b> PSET-5 - Exploratory Data Analysis (100 pts)<b></p> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca83fb",
   "metadata": {},
   "source": [
    "# This is an individual assignment. No collaboration is allowed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ec799",
   "metadata": {},
   "source": [
    "### Note: \n",
    "You are allowed to use all Python built-in functions and other Import features covered in class. Ensure your code is organized, well-commented, and follows the best practices we discussed. Remember, the key is not just to write a working program but to produce a solution that follows SPECS, is easy to debug, and is easy to maintain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41163e5e",
   "metadata": {},
   "source": [
    "### Assignment Question List:\n",
    " \n",
    "**Question 1 : Data Extraction and cleaning (1 pts)**\n",
    "\n",
    "**Question 2 : Column Cleaning Function (15 pts)**\n",
    "\n",
    "**Question 3 : Data Cleaning (9 pts)**\n",
    "\n",
    "**Question 4 : Data Aggregation (30 pts)**\n",
    "\n",
    "**Question 5 : Merging Data (10 pts)**\n",
    "\n",
    "**Question 6 : Filtering Data (30 pts)**\n",
    "\n",
    "**Coding Style : (5 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab336b0",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "**You are tasked with performing detailed exploratory data analysis on various system datasets: CPU, Disk, and Memory. Utilize Python functions to streamline data extraction, cleaning, and aggregation.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32b9bd",
   "metadata": {},
   "source": [
    "### Datasets:\n",
    "\n",
    "1. **CPU Dataset: `cpu.csv`**\n",
    "   - **Columns:** 'Image', 'PID', 'Description', 'Status', 'Threads', 'CPU', 'Average CPU'\n",
    "   <br><br>\n",
    "2. **Disk Dataset: `disk.csv`**\n",
    "   - **Columns:** 'Image', 'PID', 'Model', 'Read Byte Per Second', 'Write Byte Per Second', 'Delay', 'Total Byte Per Second'\n",
    "    <br><br>\n",
    "3. **Memory Dataset: `memory.csv`**\n",
    "   - **Columns:** 'Image', 'PID', 'Hard Faults/sec', 'Commit KB', 'Working Set KB', 'Shareable KB', 'Private KB'\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a89055f",
   "metadata": {},
   "source": [
    "# Your Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1d8f8",
   "metadata": {},
   "source": [
    "### 1. Data Extraction (1 pts):\n",
    "\n",
    "a. **Load `cpu.csv` into a Pandas DataFrame named `df_cpu`. Extract only these columns:** 'Image', 'PID', 'Description', 'Status', 'Threads', 'Average CPU'\n",
    "\n",
    "b. **Load `disk.csv` into a DataFrame named `df_disk`. Extract only these columns:** 'Image', 'PID', 'Total Byte Per Second'\n",
    "\n",
    "c. **Load `memory.csv` into a DataFrame named `df_memory`. Extract only these columns:** 'Image', 'PID', 'Working Set KB'\n",
    "\n",
    "d. **For each of the above data frame show the shape, and info(example : df_cpu.info())**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2abb771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here. Be sure to import packages needed!\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b822932-5984-456c-a944-5ab01338cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpu = pd.read_csv('cpu.csv', usecols=['Image', 'PID', 'Description', 'Status', 'Threads', 'Average CPU'])\n",
    "df_disk = pd.read_csv('disk.csv', usecols=['Image', 'PID', 'Total Byte Per Second'])\n",
    "df_memory = pd.read_csv('memory.csv', usecols=['Image', 'PID', 'Working Set KB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa75e715-b3d1-4fdf-b8f9-d67d2eae2c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU DataFrame:\n",
      "(306, 6)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Image        306 non-null    object \n",
      " 1   PID          306 non-null    object \n",
      " 2   Description  290 non-null    object \n",
      " 3   Status       306 non-null    object \n",
      " 4   Threads      306 non-null    object \n",
      " 5   Average CPU  306 non-null    float64\n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 14.5+ KB\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CPU DataFrame:\")\n",
    "print(df_cpu.shape)\n",
    "print(df_cpu.info())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1715134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disk DataFrame:\n",
      "(14, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 3 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Image                  14 non-null     object\n",
      " 1   PID                    14 non-null     int64 \n",
      " 2   Total Byte Per Second  14 non-null     object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 464.0+ bytes\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Disk DataFrame:\")\n",
    "print(df_disk.shape)\n",
    "print(df_disk.info())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9f838d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory DataFrame:\n",
      "(306, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Image           306 non-null    object\n",
      " 1   PID             306 non-null    int64 \n",
      " 2   Working Set KB  306 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 7.3+ KB\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Memory DataFrame:\")\n",
    "print(df_memory.shape)\n",
    "print(df_memory.info())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dec275",
   "metadata": {},
   "source": [
    "### 2. Column Cleaning Function (15 pts):\n",
    "\n",
    "a. **Write a Python function, `CleanColumnHeading(dfx)`, to clean the column headers of any Pandas dataframe. The function should be dynamic enough to be able to process any datasets. The function should:**\n",
    "\n",
    "   i. Convert all column names to lowercase.\n",
    "   \n",
    "   ii. Replace spaces in column names with underscores `_`.\n",
    "\n",
    "   iii. Apply the `CleanColumnHeading` function to `df_cpu`, `df_disk`, and `df_memory`.\n",
    "\n",
    "   iv. Show examples of the changes.  \n",
    "\n",
    "**Example:**\n",
    "\n",
    "Function header:\n",
    "```python\n",
    "def CleanColumnHeading(dfx):\n",
    "    # Your code to convert all column names to lowercase\n",
    "    # Your code to change all spaces in column names to underscores _\n",
    "    return dfx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f3b5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanColumnHeadings(dfx):\n",
    "    dfx.columns = dfx.columns.str.lower().str.replace(' ', '_')\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0392dea-7102-4a1e-baf7-afa87d823ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpu = CleanColumnHeadings(df_cpu)\n",
    "df_disk = CleanColumnHeadings(df_disk)\n",
    "df_memory = CleanColumnHeadings(df_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8db8ed38-5f06-4364-a146-825c01ea270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu dataframe columns: ['image', 'pid', 'description', 'status', 'threads', 'average_cpu']\n",
      "disk dataframe columns: ['image', 'pid', 'total_byte_per_second']\n",
      "memory dataframe columns: ['image', 'pid', 'working_set_kb']\n"
     ]
    }
   ],
   "source": [
    "print(\"cpu dataframe columns:\", df_cpu.columns.tolist())\n",
    "print(\"disk dataframe columns:\", df_disk.columns.tolist())\n",
    "print(\"memory dataframe columns:\", df_memory.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddd238f0-8152-4731-a8ba-503f5c59b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image           object\n",
      "pid             object\n",
      "description     object\n",
      "status          object\n",
      "threads         object\n",
      "average_cpu    float64\n",
      "dtype: object\n",
      "image                    object\n",
      "pid                       int64\n",
      "total_byte_per_second    object\n",
      "dtype: object\n",
      "image             object\n",
      "pid                int64\n",
      "working_set_kb    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_cpu.dtypes)\n",
    "print(df_disk.dtypes)\n",
    "print(df_memory.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e86fa-c8c8-4e50-9f75-517491d29e68",
   "metadata": {},
   "source": [
    "### 3. Data cleaning (9 pts)\n",
    "**Examine the columns 'threads', 'total_byte_per_second', 'working_set_kb' from the dataframes df_cpu, df_disk, and df_memory. We are going to work with these columns Question 4-6. Ensure that they have the correct data type, fix the values if required so. If there are invalid values drop them. At the end of this step you should not have any invalid values, and the correct data type set for the 3 columns. You are not required to do data cleaning on other columns. If you choose to do so, please ensure that no rows are dropped while cleaning these columns** \n",
    "\n",
    "**Hint: values such as 71,807 are not invalid. They are simply string representation of the number 71807. Fix it so they are stored as 71807, and the column datatype should either be a float or int.** \n",
    "\n",
    "\n",
    "**For each of the columns modified , show example rows of what was modified. Also call the info() method on each of the dataframes.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a1a8e5-9532-4624-a143-2ff579b99909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_columnn(dfx, column_name):\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984e73b-cc46-4a35-80a6-2505f28f2e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50664004-97f4-4f5e-b47b-b4c1d75cc875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8418df3f-bd4c-4179-ae8b-3b705164902a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e988c47-5362-4b97-8ae3-eb77936239c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2dfeac-b063-42c6-aa4f-8b610f8a9059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643c610-ea2f-462e-ba41-bf0a16b20428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90df9d5d",
   "metadata": {},
   "source": [
    "### 4. Data Aggregation (30 pts):\n",
    "\n",
    "a. **Develop an `aggregate_data(dfx)` function that:**\n",
    "\n",
    "   - Accepts one of the dataframes (`df_cpu`, `df_disk`, or `df_memory`).\n",
    "   - Dynamically identifies the dataset based on its columns.\n",
    "   - Aggregates the data based on the specific dataset requirements provided below and returns an aggregated dataframe. You can name this new aggregated dataframe whatever name works (examples given).\n",
    "\n",
    "b. **Aggregation Requirements:**\n",
    "\n",
    "   i. For `df_cpu`:\n",
    "   \n",
    "          1. Group by 'image' and aggregate the 'threads' column. Use the sum() function for aggregation.\n",
    "          2. The resultant dataframe should contain: 'image_name', 'process_qty', 'threads_sum'.\n",
    "          3. Reset the index after aggregation.\n",
    "          4. Assign the new aggregated dataframe values to df_cpu_sum.\n",
    "   \n",
    "   ii. For `df_disk`:\n",
    "   \n",
    "          1. Group by 'image' and aggregate the 'total_byte_per_second' column.Use the sum() function for aggregation.\n",
    "          2. The resultant dataframe should contain: 'image_name', 'process_qty', 'total_byte_sum'.\n",
    "          3. Reset the index after aggregation.\n",
    "          4. Assign the new aggregated dataframe values to df_disk_sum.\n",
    "   \n",
    "   iii. For `df_memory`:\n",
    "   \n",
    "          1. Group by 'image' and aggregate the 'working_set_kb' column. Use the sum() function for aggregation.\n",
    "          2. The resultant dataframe should contain: 'image_name', 'process_qty', 'working_set_sum'.\n",
    "          3. Reset the index after aggregation.\n",
    "          4. Assign the new aggregated dataframe values to df_memory_sum.\n",
    "   \n",
    "   **Note: 'process_qty' is defined by grouping by 'image' and determining the number of times a particular image name occurs. Use the size() function for aggregation**\n",
    "          \n",
    "c. **Run `aggregate_data()` for each of your dataframes and save them into new dataframes. Print the head(10) and tail(10) for each of the new dataframes.**\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Function header:\n",
    "```python\n",
    "def aggregate_data(dfx):\n",
    "    # Your code aggregates the data based on the requirements provided.\n",
    "    return df_combo  # Name this resultant dataframe whatever name that works\n",
    "```\n",
    "Calling function and assigning the resultant dataframe to `df_cpu_sum`, `df_disk_sum`, `df_memory_sum`:\n",
    "```python\n",
    "df_cpu_sum = aggregate_data(df_cpu)\n",
    "df_disk_sum = aggregate_data(df_disk)\n",
    "df_memory_sum = aggregate_data(df_memory)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bafe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdd382-6058-453c-a951-d3b6b031b871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0187d-8897-4b4d-ba32-6e33fe041600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f02b52-0dd7-4c47-93fd-2e0097c5a5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ddf03-9bd5-4635-a2ed-c4235bb31500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302de26-0c2f-41db-ab72-1dddb44d0162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9700e5e-c3f2-4f40-8fc5-eda9032517fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "919d504b",
   "metadata": {},
   "source": [
    "### 5. Merging Data (10 pts):\n",
    "\n",
    "a. **Use the Pandas merge function to do an inner join on 'image_name' for dataframes `df_cpu_sum` and `df_disk_sum` created in the previous step. Store the result in a dataframe named `df_new`**.\n",
    "\n",
    "b. **Further merge `df_new` with `df_memory_sum` using an inner join on 'image_name'**.\n",
    "\n",
    "c. **Show the resulting dataframe in each of the steps above**\n",
    "\n",
    "Please refer to the pandas merge method and its parameters here : https://pandas.pydata.org/docs/reference/api/pandas.merge.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e6d66-af7c-4959-9143-bcd234c8ab2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1322167a-c525-41e0-a4f1-1bcef7b39d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e67a348",
   "metadata": {},
   "source": [
    "### 6. Filtering Data (30 pts):\n",
    "\n",
    "a. **Filter `df_new` to obtain:**\n",
    "\n",
    "   i. `image_name` that had 'working_set_sum' greater than 200,000. Store the result in a variable named 'high_memory_image'.\n",
    "\n",
    "   ii. `image_name` that had 'thread_sum' greater than 200. Store the result in a variable named 'high_thread_image'.\n",
    "\n",
    "   iii. `image_name` that had 'working_set_sum' greater than 200,000, 'thread_sum' less than 50, and 'total_byte_sum' less than 7,000. Store the result in a variable named 'hi_mem_low_thread_low_io'.\n",
    "   \n",
    "   iv. Show each of the filtered dataframe in separate cells. Feel free to add new cells to this notebook.  \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dffad5-3660-4eca-9d52-b35dd2722848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your  code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de6121-fa03-42d5-a3b3-aa7d3a1d2dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577a033-4047-4c1f-bc4e-9e3017109b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f08e3-1fd7-4baa-8391-8f94b5d916bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8e545-0115-44c6-8eb9-71a814fc2900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7cfcc-bc48-4fd6-a027-c46e3fede9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4689a423-34ed-4a5f-be52-a52a4d579d35",
   "metadata": {},
   "source": [
    "### Coding Style (5 pts) \n",
    "Although we do not enforce a coding style such as PEP 8 (https://peps.python.org/pep-0008/) , please ensure that you have comments for each of the functions defined. Your code is readable, and includes only the code that is required by the assignment. Please remove any commented code, and experimental code that you may have tried. For each of the questions be sure to show some example rows of the dataframe that was modified or created.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b6af8-6b20-428a-b763-a4962c5de8bb",
   "metadata": {},
   "source": [
    "## Submission on Gradescope\n",
    "\n",
    "**Gradescope canvas left menu -> Gradescop -> PSET 5: Exploratory Data Analysis**\n",
    "\n",
    "**Submission :**\n",
    "Submit the jupyter notebook, and a pdf version of this notebook.\n",
    "\n",
    "To create a pdf of this notebook :  In your browser open print, and save as pdf. Name the pdf LastNameFirstName_pset5.pdf\n",
    "example: DoeJohn_pset5.pdf\n",
    "\n",
    "Name this jupyter notebook with the same format LastNameFirstName_pset5.ipynb\n",
    "\n",
    "Make sure that your notebook has been run before creating pdf. Any outputs from running the code needs to be clearly visible. We need both .ipynb, and pdf of this notebook to assign you grades. \n",
    "\n",
    "Drop all the files in gradescope under PSET 5: Exploratory Data Analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10836d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
